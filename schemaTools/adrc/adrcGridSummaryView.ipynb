{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "## The neuropath data at Emory ADRC is currently not particularly well organized\n",
    "## and naming schema is inconsistent.  Working on developing a schema \n",
    "import girder_client\n",
    "import os,sys, json\n",
    "import dagSecrets as dgs\n",
    "from collections import Counter\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "# import pandas as pd\n",
    "import pickle\n",
    "import brain_region_maps as brm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import adrcSchemaHelpers as hlprs\n",
    "import brain_region_maps as brn\n",
    "gc = girder_client.GirderClient(apiUrl=dgs.cbApiUrl)\n",
    "gc.authenticate(apiKey=dgs.cbApiToken)\n",
    "\n",
    "from pivottablejs import pivot_ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELOADING DATA\n",
      "[{'_accessLevel': 2, '_id': '61cdda2d5aef3e5525a0e90e', '_modelType': 'collection', '_textScore': 11.0, 'created': '2021-12-30T16:11:25.674000+00:00', 'description': '', 'meta': {}, 'name': 'ADRC_Data_from_APOLLO', 'public': False, 'size': 51585345300713, 'updated': '2021-12-30T16:11:25.674000+00:00'}]\n"
     ]
    }
   ],
   "source": [
    "npPickleFile = 'npDemoData.pickle'\n",
    "savePickle = True\n",
    "reload = True\n",
    "\n",
    "if os.path.isfile(npPickleFile) and not reload:\n",
    "    with open(npPickleFile,\"rb\") as fp:\n",
    "        npSlideDict=  pickle.load(fp)\n",
    "else:\n",
    "    print(\"RELOADING DATA\")\n",
    "    npSlideDict = hlprs.getADRCcollection(gc,rootCollectionName='ADRC_Data_from_APOLLO')\n",
    "    if savePickle:\n",
    "        with open(npPickleFile,\"wb\") as fp:\n",
    "            pickle.dump(npSlideDict,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npSlideDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd = []\n",
    "needsMap = []\n",
    "\n",
    "for k in npSlideDict:\n",
    "    yr = int(k.split(\"_\")[0])\n",
    "    caseId = k.split(\"_\")[1]\n",
    "    caseSet = npSlideDict[k]\n",
    "    if caseId not in brn.MAP:\n",
    "        dfd.append({'Year':yr,'caseID':caseId,'totalSlidesInDir':len(caseSet),'validBrainMap':'No'})\n",
    "        needsMap.append(caseId)\n",
    "    elif caseId in brn.MAP:\n",
    "        dfd.append({'Year':yr,'caseID':caseId,'totalSlidesInDir':len(caseSet),'validBrainMap':'Yes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "OS94-54\n",
      "E96-33\n",
      "E08-119\n",
      "E08-146\n",
      "E09-35\n",
      "E10-83\n",
      "E14-09\n",
      "OS-140327\n",
      "OS-140909\n",
      "OS-141217\n",
      "OSWH-140318\n",
      "E15-00\n",
      "OS\n",
      "OS\n",
      "OS-180213\n"
     ]
    }
   ],
   "source": [
    "#pivot_ui(pd.DataFrame(dfd))\n",
    "print(len(needsMap))\n",
    "\n",
    "needPathReport = ['E21-5','E21-8','E21-16','E16-128','E16-15','E16-24','E16-27','E16-33','E16-34','E14-9','E14-6'] ## need ac opy of the path report..\n",
    "\n",
    "for m in needsMap:\n",
    "    if m not in needPathReport:\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionList = []\n",
    "for k in brm.MAP:\n",
    "    regionList += brm.MAP[k].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midbrain 220\n",
      "Parietal cortex 219\n",
      "Occipital cortex 219\n",
      "Amygdala 218\n",
      "Cingulate cortex 216\n",
      "Medulla 216\n",
      "Frontal cortex 208\n",
      "Temporal cortex 208\n",
      "Pons 208\n",
      "Cerebellum and dentate nucleus 199\n",
      "Insular cortex 187\n",
      "Anterior basal ganglia 180\n",
      "Hippocampus 173\n",
      "Upper spinal cord 167\n",
      "Lower spinal cord 165\n",
      "Left perirolandic cortex 151\n",
      "Thalamus 149\n",
      "Right perirolandic cortex 129\n",
      "Hypothalamus 122\n",
      "Mid-level basal ganglia 97\n",
      "Posterior basal ganglia 96\n",
      "Dorsal root ganglia 93\n",
      "Mid-level spinal cord 90\n",
      "Hypothalamus and thalamus 77\n",
      "Thalamus, with subthalamic nucleus 62\n",
      "Dorsal roots 48\n",
      "Ventral roots 47\n",
      "Right hippocampus 42\n",
      "Paraspinal muscle 41\n",
      "Diaphragm muscle 21\n",
      "Anterior basal ganglia and insular cortex 20\n",
      "Spinal cord 15\n",
      "Dorsal root ganglion 14\n",
      "Insular cortex and anterior basal ganglia 12\n",
      "Posterior basal ganglia and hypothalamus 12\n",
      "Basal ganglia 10\n",
      "Cerebellum 9\n",
      "Cerebellar cortex and dentate nucleus 5\n",
      "Cingulate cortex with possible ventricular shunt 2\n",
      "Mid-level basal ganglia and hypothalamus 2\n",
      "Peri-rolandic cortex 2\n",
      "Left periRonaldic cortex 2\n",
      "Dura, with superior sagittal sinus and calcifications 1\n",
      "Possible area of infraction, inferior frontal cortex 1\n",
      "Possible area of infection, lateral occipital cortex 1\n",
      "Posterior communicating artery 1\n",
      "Left posterior communicating artery 1\n",
      "Dura at site of incesion 1\n",
      "Sections of arachnoid 1\n",
      "Sections of bilateral posterior cerebral arteries 1\n",
      "Posterior basalganglia and hypothalamus 1\n",
      "Insular cortex and anterior basal ganglia with nucleus accumbens 1\n",
      "Sections of right posterior cerebral and left posterior communicating arteries 1\n",
      "Left anterior basal ganglia with small lesions 1\n",
      "Right anterior basal ganglia with lesions 1\n",
      "Right Hippocampus 1\n",
      "Cerebellar white matter with areas of hemorrhage 1\n",
      "Dura with subdural hemorrhage 1\n"
     ]
    }
   ],
   "source": [
    "x= []\n",
    "\n",
    "for k,v in Counter(regionList).most_common():\n",
    "    if k not in brn.cleanupKeys and k not in brn.nonSchemaRegions:\n",
    "    \n",
    "        print(k,v)\n",
    "        x.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## meta.region  meta.stain  meta.subject\n",
    "basicSlideInfo = []\n",
    "mdKeys = ['region','stain','subject','brain_region']\n",
    "\n",
    "for subjyr in npSlideDict:\n",
    "    for s in npSlideDict[subjyr]:\n",
    "        slideData = {'folderId': subjyr,'slideName':s['name'],'itemId':s['_id']}\n",
    "        \n",
    "        for k in mdKeys:\n",
    "            if k in s['meta']:\n",
    "                slideData[k] = s['meta'][k]\n",
    "        basicSlideInfo.append(slideData)\n",
    "pd.DataFrame(basicSlideInfo).to_csv(\"adrcInitialMetadataExport.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npByYearCase = {}\n",
    "for k in npSlideDict:\n",
    "    try:\n",
    "        (year,caseId) = k.split(\"_\")\n",
    "        if year not in npByYearCase:\n",
    "            npByYearCase[year]= []\n",
    "            \n",
    "        npByYearCase[year].append(caseId)\n",
    "        \n",
    "    except:\n",
    "        print(\"Weird pattern for\",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Dropdown, interactive, HBox, interactive_output\n",
    "from collections import Counter\n",
    "npYearList = list(npByYearCase.keys())\n",
    "\n",
    "dpYear = Dropdown(options=npYearList,description='Year')\n",
    "dpCaseId = Dropdown(options=npByYearCase[npYearList[0]],description='CaseId')\n",
    "\n",
    "\n",
    "def on_change(*args):\n",
    "    value = dpYear.value\n",
    "    dpCaseId.options = npByYearCase[value]\n",
    "dpYear.observe(on_change, names='value')\n",
    "\n",
    "def analyzeNpCase(year, caseId):\n",
    "    print(\"Gutman needs a bath\")\n",
    "    ### This will perform an analysis of a folder of images to see the number of slides \n",
    "    ## And check the metadata\n",
    "    npKey = \"%s_%s\" % ( year,caseId)\n",
    "    slideList = npSlideDict[npKey]\n",
    "    \n",
    "    ## Keys of interest\n",
    "    koi = ['region','regionId','subject','stain','Stain','Region']\n",
    "    slideKeys = {}\n",
    "    for k in koi:\n",
    "        slideKeys[k]= []\n",
    "    \n",
    "    caseMeta = [] ## \n",
    "    d=caseMeta ## Exposing this as a global\n",
    "    \n",
    "    for s in slideList:\n",
    "        meta = s['meta']\n",
    "        for k in meta:\n",
    "            if k in koi:\n",
    "                slideKeys[k].append(meta[k])\n",
    "        caseMeta.append( hlprs.validateSlide(s,caseId) )\n",
    "                \n",
    "                \n",
    "    ## Now go through and make things into counters so it's easier to see\n",
    "    for k in koi:\n",
    "        slideKeys[k] = Counter(slideKeys[k])\n",
    "                \n",
    "    print(\"Unique RegionId Count: %d \\t Distinct SubjID: \\t%d\"% (len(slideKeys['region']),len(slideKeys['subject'])))\n",
    "    print(\"Total slides found: %d\" % len(slideList))  ## Will add in schema maps as well\n",
    "    df = pd.DataFrame(caseMeta)\n",
    "#     print(df)\n",
    "    if 'region' in df.columns:\n",
    "        print(df.region.value_counts())\n",
    "    else:\n",
    "        print(\"region tag not found..\")\n",
    "        print([s['name'] for s in slideList])\n",
    "\n",
    "    \n",
    "ui = HBox([dpYear,dpCaseId])\n",
    "w = interactive_output(analyzeNpCase, {'year':dpYear, 'caseId':dpCaseId})\n",
    "display(ui,w)\n",
    "\n",
    "## Key I am interested in is npSchema going forward\n",
    "## Need to figure out what to do with control slides..  will add a key to the Schema that's optional called controlSlide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brm.MAP['A18-07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LEt's examine a specific case...  2020_E20-106\n",
    "import re\n",
    "\n",
    "caseId = '2020_E20-106'\n",
    "npSlideDict[caseId]\n",
    "\n",
    "adrcName_re = re.compile('(?P<subject>.\\d\\d-\\d+)_(?P<blockID>\\d+) (?P<stain>.*)\\.[svs|ndpi]')\n",
    "\n",
    "## Let me look at the filenames in this dictionary\n",
    "for slideName in [x['name'] for x in npSlideDict[caseId]]:\n",
    "    m =  adrcName_re.search(slideName)\n",
    "    if m:\n",
    "        print(slideName,m.groupdict())\n",
    "    elif ('CON' in slideName.upper() ):  ### This is probably a control slide\n",
    "        print(\"Control slide?\",slideName)\n",
    "    else:\n",
    "        print(\"Shit nothing works\",slideName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brm.MAP['A20-11']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
