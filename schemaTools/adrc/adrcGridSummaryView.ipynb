{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## The neuropath data at Emory ADRC is currently not particularly well organized\n",
    "## and naming schema is inconsistent.  Working on developing a schema \n",
    "import girder_client\n",
    "import os,sys, json\n",
    "import dagSecrets as dgs\n",
    "from collections import Counter\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "# import pandas as pd\n",
    "import pickle\n",
    "import brain_region_maps as brm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import adrcSchemaHelpers as hlprs\n",
    "import brain_region_maps as brn\n",
    "gc = girder_client.GirderClient(apiUrl=dgs.cbApiUrl)\n",
    "gc.authenticate(apiKey=dgs.cbApiKey)\n",
    "\n",
    "from pivottablejs import pivot_ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELOADING DATA\n"
     ]
    }
   ],
   "source": [
    "npPickleFile = 'npDemoData.pickle'\n",
    "savePickle = True\n",
    "reload = True\n",
    "\n",
    "if os.path.isfile(npPickleFile) and not reload:\n",
    "    with open(npPickleFile,\"rb\") as fp:\n",
    "        npSlideDict=  pickle.load(fp)\n",
    "else:\n",
    "    print(\"RELOADING DATA\")\n",
    "    npSlideDict = hlprs.getADRCcollection(gc,rootCollectionName='ARMIN_Working_Cases')\n",
    "    if savePickle:\n",
    "        with open(npPickleFile,\"wb\") as fp:\n",
    "            pickle.dump(npSlideDict,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd = []\n",
    "needsMap = []\n",
    "\n",
    "for k in npSlideDict:\n",
    "    yr = int(k.split(\"_\")[0])\n",
    "    caseId = k.split(\"_\")[1]\n",
    "    caseSet = npSlideDict[k]\n",
    "    if caseId not in brn.MAP:\n",
    "        dfd.append({'Year':yr,'caseID':caseId,'totalSlidesInDir':len(caseSet),'validBrainMap':'No'})\n",
    "        needsMap.append(caseId)\n",
    "    elif caseId in brn.MAP:\n",
    "        dfd.append({'Year':yr,'caseID':caseId,'totalSlidesInDir':len(caseSet),'validBrainMap':'Yes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['E14-09',\n",
       " 'OS-140327',\n",
       " 'OS-140909',\n",
       " 'OS-141217',\n",
       " 'OSWH-140318',\n",
       " 'E16-128',\n",
       " 'E16-15',\n",
       " 'E16-24',\n",
       " 'E16-27',\n",
       " 'E16-33',\n",
       " 'E16-34',\n",
       " 'OS',\n",
       " 'OS',\n",
       " 'OS-180213']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pivot_ui(pd.DataFrame(dfd))\n",
    "print(len(needsMap))\n",
    "needsMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionList = []\n",
    "for k in brm.MAP:\n",
    "    regionList += brm.MAP[k].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= []\n",
    "\n",
    "for k,v in Counter(regionList).most_common():\n",
    "    if k not in brn.cleanupKeys and k not in brn.nonSchemaRegions:\n",
    "    \n",
    "        print(k,v)\n",
    "        x.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## meta.region  meta.stain  meta.subject\n",
    "basicSlideInfo = []\n",
    "mdKeys = ['region','stain','subject','brain_region']\n",
    "\n",
    "for subjyr in npSlideDict:\n",
    "    for s in npSlideDict[subjyr]:\n",
    "        slideData = {'folderId': subjyr,'slideName':s['name'],'itemId':s['_id']}\n",
    "        \n",
    "        for k in mdKeys:\n",
    "            if k in s['meta']:\n",
    "                slideData[k] = s['meta'][k]\n",
    "        basicSlideInfo.append(slideData)\n",
    "pd.DataFrame(basicSlideInfo).to_csv(\"adrcInitialMetadataExport.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npByYearCase = {}\n",
    "for k in npSlideDict:\n",
    "    try:\n",
    "        (year,caseId) = k.split(\"_\")\n",
    "        if year not in npByYearCase:\n",
    "            npByYearCase[year]= []\n",
    "            \n",
    "        npByYearCase[year].append(caseId)\n",
    "        \n",
    "    except:\n",
    "        print(\"Weird pattern for\",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Dropdown, interactive, HBox, interactive_output\n",
    "from collections import Counter\n",
    "npYearList = list(npByYearCase.keys())\n",
    "\n",
    "dpYear = Dropdown(options=npYearList,description='Year')\n",
    "dpCaseId = Dropdown(options=npByYearCase[npYearList[0]],description='CaseId')\n",
    "\n",
    "\n",
    "def on_change(*args):\n",
    "    value = dpYear.value\n",
    "    dpCaseId.options = npByYearCase[value]\n",
    "dpYear.observe(on_change, names='value')\n",
    "\n",
    "def analyzeNpCase(year, caseId):\n",
    "    print(\"Gutman needs a bath\")\n",
    "    ### This will perform an analysis of a folder of images to see the number of slides \n",
    "    ## And check the metadata\n",
    "    npKey = \"%s_%s\" % ( year,caseId)\n",
    "    slideList = npSlideDict[npKey]\n",
    "    \n",
    "    ## Keys of interest\n",
    "    koi = ['region','regionId','subject','stain','Stain','Region']\n",
    "    slideKeys = {}\n",
    "    for k in koi:\n",
    "        slideKeys[k]= []\n",
    "    \n",
    "    caseMeta = [] ## \n",
    "    d=caseMeta ## Exposing this as a global\n",
    "    \n",
    "    for s in slideList:\n",
    "        meta = s['meta']\n",
    "        for k in meta:\n",
    "            if k in koi:\n",
    "                slideKeys[k].append(meta[k])\n",
    "        caseMeta.append( hlprs.validateSlide(s,caseId) )\n",
    "                \n",
    "                \n",
    "    ## Now go through and make things into counters so it's easier to see\n",
    "    for k in koi:\n",
    "        slideKeys[k] = Counter(slideKeys[k])\n",
    "                \n",
    "    print(\"Unique RegionId Count: %d \\t Distinct SubjID: \\t%d\"% (len(slideKeys['region']),len(slideKeys['subject'])))\n",
    "    print(\"Total slides found: %d\" % len(slideList))  ## Will add in schema maps as well\n",
    "    df = pd.DataFrame(caseMeta)\n",
    "#     print(df)\n",
    "    if 'region' in df.columns:\n",
    "        print(df.region.value_counts())\n",
    "    else:\n",
    "        print(\"region tag not found..\")\n",
    "        print([s['name'] for s in slideList])\n",
    "\n",
    "    \n",
    "ui = HBox([dpYear,dpCaseId])\n",
    "w = interactive_output(analyzeNpCase, {'year':dpYear, 'caseId':dpCaseId})\n",
    "display(ui,w)\n",
    "\n",
    "## Key I am interested in is npSchema going forward\n",
    "## Need to figure out what to do with control slides..  will add a key to the Schema that's optional called controlSlide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brm.MAP['A18-07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LEt's examine a specific case...  2020_E20-106\n",
    "import re\n",
    "\n",
    "caseId = '2020_E20-106'\n",
    "npSlideDict[caseId]\n",
    "\n",
    "adrcName_re = re.compile('(?P<subject>.\\d\\d-\\d+)_(?P<blockID>\\d+) (?P<stain>.*)\\.[svs|ndpi]')\n",
    "\n",
    "## Let me look at the filenames in this dictionary\n",
    "for slideName in [x['name'] for x in npSlideDict[caseId]]:\n",
    "    m =  adrcName_re.search(slideName)\n",
    "    if m:\n",
    "        print(slideName,m.groupdict())\n",
    "    elif ('CON' in slideName.upper() ):  ### This is probably a control slide\n",
    "        print(\"Control slide?\",slideName)\n",
    "    else:\n",
    "        print(\"Shit nothing works\",slideName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brm.MAP['A20-11']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
